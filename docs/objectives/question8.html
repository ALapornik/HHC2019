

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>8) Bypassing the Frido Sleigh CAPTEHA &mdash; HHC2019  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9) Retrieve Scraps of Paper from Server" href="question9.html" />
    <link rel="prev" title="7) Get Access To The Steam Tunnels" href="question7.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> HHC2019
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Objectives:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="question0.html">0) Talk to Santa in the Quad</a></li>
<li class="toctree-l1"><a class="reference internal" href="question1.html">1) Find the Turtle Doves</a></li>
<li class="toctree-l1"><a class="reference internal" href="question2.html">2) Unredact Threatening Document</a></li>
<li class="toctree-l1"><a class="reference internal" href="question3.html">3) Windows Log Analysis: Evaluate Attack Outcome</a></li>
<li class="toctree-l1"><a class="reference internal" href="question4.html">4) Windows Log Analysis: Determine Attacker Technique</a></li>
<li class="toctree-l1"><a class="reference internal" href="question5.html">5) Network Log Analysis: Determine Compromised System</a></li>
<li class="toctree-l1"><a class="reference internal" href="question6.html">6) Splunk</a></li>
<li class="toctree-l1"><a class="reference internal" href="question7.html">7) Get Access To The Steam Tunnels</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8) Bypassing the Frido Sleigh CAPTEHA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#challenge">Challenge</a></li>
<li class="toctree-l2"><a class="reference internal" href="#answer">Answer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#solution">Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#discovery">1. Discovery</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#starting-artefacts">Starting artefacts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#solving-the-challenge">2. Solving the challenge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#constructing-the-python-environment">Constructing the Python environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-the-model">Training the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-the-model-to-solve-the-challenge">Using the model to solve the challenge</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="question9.html">9) Retrieve Scraps of Paper from Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="question10.html">10) Recover Cleartext Document</a></li>
<li class="toctree-l1"><a class="reference internal" href="question11.html">11) Open the Sleigh Shop Door</a></li>
<li class="toctree-l1"><a class="reference internal" href="question12.html">12) Filter Out Poisoned Sources of Weather Data</a></li>
</ul>
<p class="caption"><span class="caption-text">Terminals:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../terminals/EscapeEd.html">Escape Ed &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/LinuxPath.html">Linux Path &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/XmasCheerLaser.html">Xmas Cheer Laser &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/FrostyKeypad.html">Frosty Keypad &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/HolidayHackTrail.html">Holiday Hack Trail &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/Nyanshell.html">Nyanshell &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/Graylog.html">Graylog &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/MongoPilfer.html">Mongo Pilfer &lt;&gt;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/SmartBraces.html">Smart Braces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../terminals/ZeekJSONAnalysis.html">Zeek JSON Analysis &lt;&gt;</a></li>
</ul>
<p class="caption"><span class="caption-text">Appendices:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendices/narrative.html">Narrative</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">HHC2019</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>8) Bypassing the Frido Sleigh CAPTEHA</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="bypassing-the-frido-sleigh-capteha">
<h1>8) Bypassing the Frido Sleigh CAPTEHA<a class="headerlink" href="#bypassing-the-frido-sleigh-capteha" title="Permalink to this headline">¶</a></h1>
<div class="section" id="challenge">
<h2>Challenge<a class="headerlink" href="#challenge" title="Permalink to this headline">¶</a></h2>
<p>Difficulty: 4/5</p>
<p>Help Krampus beat the Frido Sleigh contest. For hints on achieving this objective, please talk with Alabaster Snowball in the Speaker Unpreparedness Room.</p>
</div>
<div class="section" id="answer">
<h2>Answer<a class="headerlink" href="#answer" title="Permalink to this headline">¶</a></h2>
<p><strong>8Ia8LiZEwvyZr2WO</strong></p>
</div>
<div class="section" id="solution">
<h2>Solution<a class="headerlink" href="#solution" title="Permalink to this headline">¶</a></h2>
<div class="section" id="discovery">
<h3>1. Discovery<a class="headerlink" href="#discovery" title="Permalink to this headline">¶</a></h3>
<p>To solve this challenge we had to utilise <strong>Machine Learning</strong> to solve a CAPTEHA security challenge and then submit as many entries as possible in the <a class="reference external" href="https://fridosleigh.com/">Frido Sleigh contest</a>.</p>
<p>You may be asking what is a CAPTEHA security challenge. The best way to answer this is with a couple of images taken from the Frido Sleigh website.</p>
<p>The first image was obtained by clicking on the privacy terms of the CAPTEHA control and provides a desription about what it is.</p>
<img alt="../_images/o8-capteha.png" src="../_images/o8-capteha.png" />
<p>The second image provides an example of the control in action. We had approx 5 seconds to identify all the correct images (from a set of 100 images). The control consists of 6 categories of images (candy canes, christmas trees, ornaments, presents, santa hats and stockings).</p>
<img alt="../_images/o8-capteha-example.png" src="../_images/o8-capteha-example.png" />
<div class="section" id="starting-artefacts">
<h4>Starting artefacts<a class="headerlink" href="#starting-artefacts" title="Permalink to this headline">¶</a></h4>
<p>The hint titled <strong>Machine Learning</strong> provided by Alabaster Snowball formed an essential part of <strong>how</strong> to solve the challenge. The hint points to a YouTube presentation by Chris Davis titled <a class="reference external" href="https://youtu.be/jmVPLwjm_zs">Machine Learning Use Cases for Cyber Security</a>. Chris provided some very useful Python code in the following <a class="reference external" href="https://github.com/chrisjd20/img_rec_tf_ml_demo">repository</a> that we later adapted to solve the CAPTEHA control. This code provided an example of using machine learning with image recognition to distinguish apples from bananas based on Python and the TensorFlow (v1.15) library.</p>
<p>In addition, we had the following resources which were provided by Krampus when he spoke about the challenge:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://downloads.elfu.org/capteha_images.tar.gz">Training images</a></p></li>
<li><p><a class="reference external" href="https://downloads.elfu.org/capteha_api.py">Fridosleigh.com CAPTEHA API</a></p></li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="solving-the-challenge">
<h3>2. Solving the challenge<a class="headerlink" href="#solving-the-challenge" title="Permalink to this headline">¶</a></h3>
<div class="section" id="constructing-the-python-environment">
<h4>Constructing the Python environment<a class="headerlink" href="#constructing-the-python-environment" title="Permalink to this headline">¶</a></h4>
<p>We created a Python virtual environment in our project directory with all the libraries that were needed by the Machine Learning example. To recreate Python virtual environment please follow the following steps from a Windows 10 computer with <strong>Python 3.7.5</strong>:</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The code in the <a class="reference external" href="https://github.com/chrisjd20/img_rec_tf_ml_demo">repository from Chris Davis</a>, which we used as the basis of our solution, has a dependency on TensorFlow 1.1.5. We found that this didn’t work with Python 3.8.x and had to revert back to a Python 3.7.5 environment.</p>
</div>
<ol class="arabic">
<li><p>Download the documentation repository from the following link: ` &lt;<a class="reference external" href="https://github.com/alapornik/HHC2019">https://github.com/alapornik/HHC2019</a>&gt;`_.</p></li>
<li><p>Open a PowerShell prompt and navigate to the <strong>/source/o8-capteha/</strong> folder</p></li>
<li><p>Enter the following command to create a virtual environment:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">venv</span> <span class="pre">.\.venv</span></code></p>
</div></blockquote>
</li>
<li><p>Activate the virtual environment by entering the following command:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">.\.venv\Scripts\Activate.ps1</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">deactivate</span></code> command to deactivate the virtual environment.</p>
</div>
</div></blockquote>
</li>
<li><p>Install the needed modules using the following command:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-r</span> <span class="pre">.\requirements.txt</span></code></p>
</div></blockquote>
</li>
<li><p>Download and extract the <a class="reference external" href="https://downloads.elfu.org/capteha_images.tar.gz">training images archive</a> into the <strong>/source/o8-capteha/training_images/</strong> folder. The folder structure of <strong>training_images</strong> should resemble the following:</p>
<blockquote>
<div><img alt="../_images/o8-training_images.png" src="../_images/o8-training_images.png" />
</div></blockquote>
</li>
<li><p>Edit the <strong>o8-capteha.py</strong> script in a text editor and modify the <strong>yourREALemailAddress</strong> variable with your email address.</p></li>
</ol>
</div>
<div class="section" id="training-the-model">
<h4>Training the model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">¶</a></h4>
<p>The first step is to undertake what’s called <strong>supervised learning</strong> where the goal is to learn the relationship between training inputs and training targets. For the challenge this means running the <strong>retrain.py</strong> script so the model can distinguish between the 6 categories of images (candy canes, christmas trees, ornaments, presents, santa hats and stockings).</p>
<p>We took advantage of the <a class="reference external" href="https://downloads.elfu.org/capteha_images.tar.gz">training images</a> supplied by Krampus.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We also wrote a script (sorry, we didn’t have time to tidy up this script and include it in our repository) that saved all the images to disk with names that reflected the image category and a unique ID. If needed we could have used multiple runs of this solution to build a training set of images.</p>
</div>
<p>Our first efforts utilised the default Inception v3 model. We found this model to be accurate but far to slow with the limited computing resources we had available. Predicting the images in the CAPTEHA challenge with this model took almost 40 seconds which was well beyond the 5 second deadline.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Testing indicated that the actual deadline to submit an answer via the API was actually 10 seconds.</p>
</div>
<p>We tried upgrading our display drivers and even installed the Nvidia CUDA package on our computer in an effort to make TensorFlow utilise GPU resources. This was complicated because the TensorFlow v1.15 framework needed specific drivers that weren’t part of current CUDA packages. We finally succeeded locating and installing all the needed drivers. Unfortunately, this effort was not successful with the CAPTEHA prediction still taking approximately 40 seconds. For some reason TensorFlow was not taking advantage of our GPU. This could have been either a software or hardware issue and decided to look for a different method of reducing the prediction time.</p>
<p>We then did some more research and discovered the possibility of utilising alternative models that were designed for resource restricted environments. These models would be faster with a tradeoff in accuracy. We tried using a MobileNet floating model as documented in the <strong>retrain.py</strong> code. Having this documentation was ideal for us because we were sensitive to possible compatibility issues with the older TensorFlow v1.15 framework. The following image shows the specific documentation referring to this in the <strong>retrain.py</strong> script.</p>
<img alt="../_images/o8-alternative-model.png" src="../_images/o8-alternative-model.png" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A side effect of changing the model was that we had to change the code in our solution (<strong>o8-capteha.py</strong>) to utilise the new model. The change involved modifying the <strong>input_height</strong> and <strong>input_width</strong> parameter defaults from 132 to 224.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="k">def</span> <span class="nf">read_tensor_from_image_bytes</span><span class="p">(</span><span class="n">imagebytes</span><span class="p">,</span> <span class="n">input_height</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">input_width</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">input_mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_std</span><span class="o">=</span><span class="mi">255</span><span class="p">):</span>
</span>    <span class="n">image_reader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">decode_png</span><span class="p">(</span> <span class="n">imagebytes</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;png_reader&quot;</span><span class="p">)</span>
    <span class="n">float_caster</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">image_reader</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">dims_expander</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">float_caster</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">resized</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_bilinear</span><span class="p">(</span><span class="n">dims_expander</span><span class="p">,</span> <span class="p">[</span><span class="n">input_height</span><span class="p">,</span> <span class="n">input_width</span><span class="p">])</span>
    <span class="n">normalized</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="p">[</span><span class="n">input_mean</span><span class="p">]),</span> <span class="p">[</span><span class="n">input_std</span><span class="p">])</span>
    <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">normalized</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
<p>We used the following command to train our model:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">.\retrain.py</span> <span class="pre">--image_dir</span> <span class="pre">.\training_images\</span> <span class="pre">--tfhub_module</span> <span class="pre">https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/3</span></code></p>
</div></blockquote>
<p>This process can take several minutes to complete and can spit out a lot of error message which can be ignored. Most of the errors we encountered were warnings about using deprecated features and issues related to the GPU.</p>
</div>
<div class="section" id="using-the-model-to-solve-the-challenge">
<h4>Using the model to solve the challenge<a class="headerlink" href="#using-the-model-to-solve-the-challenge" title="Permalink to this headline">¶</a></h4>
<p>We ran the model against the CAPTEHA challenge and entered the Frido Sleigh contest using the following command:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">.\o8-capteha.py</span></code></p>
</div></blockquote>
<p>It took a few attempts before the script was successful. We eventually received the following email message from the Frido Sleigh server:</p>
<img alt="../_images/o8-winning-entry.png" src="../_images/o8-winning-entry.png" />
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="question9.html" class="btn btn-neutral float-right" title="9) Retrieve Scraps of Paper from Server" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="question7.html" class="btn btn-neutral float-left" title="7) Get Access To The Steam Tunnels" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Peter and Antonios Lapornik

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>